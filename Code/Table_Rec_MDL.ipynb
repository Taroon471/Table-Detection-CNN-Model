{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBbzBmbC6KJy",
        "outputId": "51470b30-247a-45f4-e4f8-ec9a31630c31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = \"/content/drive/My Drive/archive.zip\"  # Update if needed\n",
        "extract_path = \"/content/sample_data/ML_DATA\"\n",
        "\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Extraction completed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-wKdtFp60Ax",
        "outputId": "85651b9c-764e-4816-d8f8-bd6fe6bd2707"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VvfpbcntZFZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Define paths\n",
        "DATASET_PATH = \"/content/sample_data/ML_DATA/subset\"  # Change this to your dataset path\n",
        "IMAGE_DIRS = {\n",
        "    \"train\": os.path.join(DATASET_PATH, \"img_train\"),\n",
        "    \"val\": os.path.join(DATASET_PATH, \"img_val\"),\n",
        "    \"test\": os.path.join(DATASET_PATH, \"img_test\"),\n",
        "}\n",
        "ANNOTATION_DIRS = {\n",
        "    \"train\": os.path.join(DATASET_PATH, \"words_train\"),\n",
        "    \"val\": os.path.join(DATASET_PATH, \"words_val\"),\n",
        "    \"test\": os.path.join(DATASET_PATH, \"words_test\"),\n",
        "}\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "c8-Jkquf70W5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.utils import Sequence\n",
        "\n",
        "\n",
        "# Step 1: Data Generator for Table Detection\n",
        "class DataGenerator(Sequence):\n",
        "    def __init__(self, img_folder, json_folder, batch_size, img_size=(128, 128)):\n",
        "        self.img_folder = img_folder\n",
        "        self.json_folder = json_folder\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.img_files = os.listdir(img_folder)\n",
        "        self.json_files = os.listdir(json_folder)\n",
        "        self.indexes = np.arange(len(self.img_files))\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.img_files) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch_indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "        batch_img_files = [self.img_files[k] for k in batch_indexes]\n",
        "        batch_json_files = [self.json_files[k] for k in batch_indexes]\n",
        "\n",
        "        X = np.zeros((len(batch_img_files), *self.img_size, 3), dtype=np.float32)\n",
        "        y = []\n",
        "\n",
        "        for i, (img_file, json_file) in enumerate(zip(batch_img_files, batch_json_files)):\n",
        "            img_path = os.path.join(self.img_folder, img_file)\n",
        "            json_path = os.path.join(self.json_folder, json_file)\n",
        "\n",
        "            # Load and resize image\n",
        "            img = Image.open(img_path).resize(self.img_size)\n",
        "            X[i] = np.array(img) / 255.0  # Normalize to [0, 1]\n",
        "\n",
        "            # Load JSON and extract bbox\n",
        "            with open(json_path, 'r') as f:\n",
        "                data = json.load(f)\n",
        "                if isinstance(data, list) and len(data) > 0:\n",
        "                    bbox = data[0]['bbox']\n",
        "                    # Normalize bbox to [0, 1]\n",
        "                    bbox = [\n",
        "                        bbox[0] / self.img_size[0],  # x_min / width\n",
        "                        bbox[1] / self.img_size[1],  # y_min / height\n",
        "                        bbox[2] / self.img_size[0],  # x_max / width\n",
        "                        bbox[3] / self.img_size[1]   # y_max / height\n",
        "                    ]\n",
        "                    y.append(bbox)\n",
        "                else:\n",
        "                    raise ValueError(f\"Invalid JSON format in {json_path}. Expected a list of dictionaries with 'bbox' key.\")\n",
        "\n",
        "        return X, np.array(y)\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        np.random.shuffle(self.indexes)"
      ],
      "metadata": {
        "id": "lvjiccHtZGQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Define the CNN Model for Table Detection\n",
        "def create_cnn_model(input_shape):\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(128, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(4)  # Output 4 values for bbox [x_min, y_min, x_max, y_max]\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Step 3: Train the Table Detection Model\n",
        "def train_table_detection_model(train_img_folder, train_json_folder, val_img_folder, val_json_folder, batch_size=12, img_size=(128, 128), epochs=5):\n",
        "    input_shape = (*img_size, 3)\n",
        "\n",
        "    # Create data generators\n",
        "    train_generator = DataGenerator(train_img_folder, train_json_folder, batch_size, img_size)\n",
        "    val_generator = DataGenerator(val_img_folder, val_json_folder, batch_size, img_size)\n",
        "\n",
        "    # Create and compile the model\n",
        "    model = create_cnn_model(input_shape)\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')  # Use MSE for regression\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(train_generator, validation_data=val_generator, epochs=epochs)\n",
        "\n",
        "    return model, history\n",
        "\n",
        "\n",
        "# Step 4: Predict Bounding Boxes for Test Images\n",
        "def predict_bboxes(model, img_folder, output_csv):\n",
        "    results = []\n",
        "\n",
        "    for img_file in os.listdir(img_folder):\n",
        "        img_path = os.path.join(img_folder, img_file)\n",
        "\n",
        "        # Load and preprocess the image\n",
        "        img = Image.open(img_path)\n",
        "        img_array = np.array(img.resize((128, 128))) / 255.0  # Resize and normalize\n",
        "        img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "\n",
        "        # Predict the bounding box\n",
        "        bbox = model.predict(img_array)[0]\n",
        "\n",
        "        # Save results\n",
        "        results.append({\n",
        "            'image': img_file,\n",
        "            'bbox': bbox\n",
        "        })\n",
        "\n",
        "\n",
        "    # Save results to a CSV file\n",
        "    import pandas as pd\n",
        "    df = pd.DataFrame(results)\n",
        "    df.to_csv(output_csv, index=False)\n",
        "    print(f\"Results saved to {output_csv}\")"
      ],
      "metadata": {
        "id": "1r5iZxjbZlv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # Step 5: Run the Pipeline\n",
        "if __name__ == \"__main__\":\n",
        "    # Paths to your data\n",
        "    train_img_folder = '/content/sample_data/ML_DATA/subset/img_train'\n",
        "    train_json_folder = '/content/sample_data/ML_DATA/subset/words_train'\n",
        "    val_img_folder = '/content/sample_data/ML_DATA/subset/img_val'\n",
        "    val_json_folder = '/content/sample_data/ML_DATA/subset/words_val'\n",
        "    test_img_folder = '/content/sample_data/ML_DATA/subset/img_test'\n",
        "    # output_csv = '/content/sample_data/ML_DATA/subset/output_bboxes.csv'\n",
        "\n",
        "    # Set batch size\n",
        "    batch_size = 12  # You can change this value\n",
        "\n",
        "    # Step 1: Train the table detection model\n",
        "    print(\"Training table detection model...\")\n",
        "    model, history = train_table_detection_model(train_img_folder, train_json_folder, val_img_folder, val_json_folder, batch_size=batch_size)\n",
        "    model.save('/content/drive/My Drive/table_detection_model.h5')\n",
        "    # # Ensure you're passing only the model to the prediction function\n",
        "    # print(\"Predicting bounding boxes for test images...\")\n",
        "    # predict_bboxes(model, test_img_folder, output_csv)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQXU4DjFbEPm",
        "outputId": "7f4ce5ad-4010-4f97-c6c0-b662118ebd4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training table detection model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m447s\u001b[0m 88ms/step - loss: 0.4804 - val_loss: 0.4733\n",
            "Epoch 2/5\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m423s\u001b[0m 85ms/step - loss: 0.4457 - val_loss: 0.4759\n",
            "Epoch 3/5\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m377s\u001b[0m 75ms/step - loss: 0.4487 - val_loss: 0.4776\n",
            "Epoch 4/5\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 73ms/step - loss: 0.4485 - val_loss: 0.4759\n",
            "Epoch 5/5\n",
            "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 72ms/step - loss: 0.4447 - val_loss: 0.4749\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    }
  ]
}